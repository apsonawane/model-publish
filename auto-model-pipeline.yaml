trigger:
 - main 

schedules: 

 - cron: "0 0 * * *" 

   displayName: Daily midnight build 

   branches: 

     include: 
       - main 

   always: true 

parameters:
 - name: model_name
   displayName: mode name on huggingface website
   type: string
   default: microsoft/Phi-3.5-mini-instruct

pool: Onnxruntime-Linux-A10-24G
steps:
 - task: UsePythonVersion@0
   inputs:
     versionSpec: '3.10'
     architecture: 'x64'

 - bash: |
     pip install -r llama-requirements.txt
   displayName: install the necessary packages
   workingDirectory: $(Build.SourcesDirectory)

 - bash: |
     echo Authenticate with Huggingface repository 

     huggingface-cli login --token "$(hf_token)"

   displayName: "Authentication to Huggingface repo" 

 - bash: |
    echo "Processing checkpoint"

    checkpoint="${{ parameters.model_name }}"

    # Replace "/" with "_" and convert to lowercase
    formatted_checkpoint=$(echo "$checkpoint" | tr '/' '_' | tr '[:upper:]' '[:lower:]')
    formatted_name=$(echo "$formatted_checkpoint" | tr '.' '_' | tr '[:upper:]' '[:lower:]')

    # Set the formatted checkpoint as an environment variable
    echo "##vso[task.setvariable variable=formatted_checkpoint]$formatted_checkpoint"
    echo "##vso[task.setvariable variable=formatted_name]$formatted_name"

    echo "Formatted checkpoint: $formatted_checkpoint"
    echo "Formatted name: $formatted_name"
   displayName: "Process checkpoint"

 - script: |
     docker run --gpus all --rm \
        --ipc=host \
        --volume $(Build.SourcesDirectory):/ort_src \
        --volume $(Build.BinariesDirectory):/build \
        -e CCACHE_DIR=/cache -w /ort_src \
        -e HF_TOKEN=$(hf_token) \
        -e MODEL_NAME=${{ parameters.model_name }} \
        ptebic.azurecr.io/public/aifx/acpt/stable-ubuntu2004-cu121-py310-torch222:biweekly.202410.2 /bin/bash /ort_src/docker_script.sh
   workingDirectory: $(Build.SourcesDirectory)
   displayName: "start model endpoint and RAI eval in container"

 - bash: |
    pip list 
   displayName: "dump pip list"

#  - task: AzureCLI@2
#    displayName: 'upload model to Blob Storage'
#    inputs:
#      azureSubscription: AIInfraBuild
#      scriptLocation: inlineScript
#      scriptType: bash
#      inlineScript: |
#        cd $(Build.SourcesDirectory)
#        ls $(Build.SourcesDirectory)
#        azcopy copy './microsoft_phi-3-mini-4k-instruct/' 'https://sunghchostorageaccount.blob.core.windows.net/test' --recursive

 - task: AzureCLI@2
   displayName: 'upload model to AzureML registry'
   inputs:
     azureSubscription: AIInfraBuild
     scriptLocation: inlineScript
     scriptType: bash
     inlineScript: |
       cd $(Build.BinariesDirectory)
       echo "Formatted checkpoint: $(formatted_checkpoint)"
       echo "Formatted name: $(formatted_name)"
       echo "Install az extension"
       az extension remove -n azure-cli-ml
       az extension remove -n ml
       az extension add --name ml
       pip install marshmallow==3.23.2 --target /mnt/vss/_work/_temp/.azclitask/cliextensions/ml --upgrade
       pip list
       az extension list
       az ml data create --name "$(formatted_name)_hf_version" --registry-name TestRegistryforModelPublish --version 0 --path "$(Build.BinariesDirectory)/oga_models/hf_version" --description "$(formatted_name)_hf_version from pipeline"
       az ml data create --name "$(formatted_name)_gpu" --registry-name TestRegistryforModelPublish --version 0 --path '$(Build.BinariesDirectory)/oga_models/microsoft_phi-3.5-mini-instruct/cuda' --description "$(formatted_name)_gpu from pipeline"
